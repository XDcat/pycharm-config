<templateSet group="环评_01">
  <template name="hp1" value="'''&#10;流程：&#10;1. parse_task: 获取task，并将数据传给get_data&#10;2. get_data: 解析页面数据，把数据存入data字典，然后传入i_api.save_huanping(data, province_id, city_id, type_id)保存数据&#10;'''&#10;from urllib.parse import urljoin&#10;from iWork.dbapi.api import get_tasks_with_cat&#10;from iWork import i_api&#10;from pprint import pprint&#10;import re&#10;&#10;# 计数&#10;count = 0&#10;# 城市信息&#10;city_id = $city_id$&#10;&#10;def parse_task_1():&#10;    # 获取本市未爬取的url&#10;    tasks = get_tasks_with_cat(province_id, city_id, 1)&#10;    for task in tasks:&#10;        # 实时播报&#10;        global count&#10;        count += 1&#10;        # 时间&#10;        p_time = task[4]&#10;        p_time = p_time.isoformat()[:10]&#10;        print(count, p_time, task[0], task[1], task[2])&#10;        # 处理数据&#10;        title = task[2]&#10;        url = task[1]&#10;        task_id = task[0]&#10;        get_data_1(url, title, p_time, task_id)&#10;    print(&quot;======city_id:{}, type_id{}======&quot;.format(city_id, 1))&#10;    print(&quot;======完成======&quot;)&#10;&#10;&#10;@i_api.exception_log(('city_id: ' + str(city_id) + 'type_id:' + str(1)))&#10;def get_data_1(url, title, public_time, task_id):&#10;    html = i_api.html_xpath(url)&#10;    # 主要内容的xpath&#10;    main_xpath = &quot;$xpath$&quot;&#10;    is_save = False&#10;    if i_api.data_is_table(html, main_xpath):&#10;        i_api.save_table_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;    elif i_api.data_is_para(html, main_xpath):&#10;        i_api.save_para_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                    min_num=8, to_save=is_save)&#10;    elif i_api.data_is_aline(html, main_xpath):&#10;        i_api.save_aline_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     min_num=8, to_save=is_save)&#10;    else:&#10;        i_api.save_title_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;&#10;&#10;if __name__ == '__main__':&#10;    parse_task_1()&#10;" description="new_获取环评1" toReformat="false" toShortenFQNames="true">
    <variable name="city_id" expression="" defaultValue="" alwaysStopAt="true" />
    <variable name="xpath" expression="" defaultValue="" alwaysStopAt="true" />
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="hp2" value="def parse_task_2():&#10;    # 获取本市未爬取的url&#10;    tasks = get_tasks_with_cat(province_id, city_id, 2)&#10;    for task in tasks:&#10;        # 实时播报&#10;        global count&#10;        count += 1&#10;        # 时间&#10;        p_time = task[4]&#10;        p_time = p_time.isoformat()[:10]&#10;        print(count, p_time, task[0], task[1], task[2])&#10;        # 处理数据&#10;        title = task[2]&#10;        url = task[1]&#10;        task_id = task[0]&#10;        get_data_2(url, title, p_time, task_id)&#10;    print(&quot;======city_id:{}, type_id{}======&quot;.format(city_id, 2))&#10;    print(&quot;======完成======&quot;)&#10;&#10;&#10;@i_api.exception_log(('city_id: ' + str(city_id) + 'type_id:' + str(2)))&#10;def get_data_2(url, title, public_time, task_id):&#10;    html = i_api.html_xpath(url)&#10;    # 主要内容的xpath&#10;    main_xpath = &quot;$xpath$&quot;&#10;    is_save = False&#10;    if i_api.data_is_table(html, main_xpath):&#10;        i_api.save_table_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;    elif i_api.data_is_para(html, main_xpath):&#10;        i_api.save_para_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                    min_num=8, to_save=is_save)&#10;    elif i_api.data_is_aline(html, main_xpath):&#10;        i_api.save_aline_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     min_num=8, to_save=is_save)&#10;    else:&#10;        i_api.save_title_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10; &#10;&#10;if __name__ == '__main__':&#10;    parse_task_2()" description="new_获取环评2" toReformat="false" toShortenFQNames="true">
    <variable name="xpath" expression="" defaultValue="" alwaysStopAt="true" />
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="hp3" value="def parse_task_3():&#10;    # 获取本市未爬取的url&#10;    tasks = get_tasks_with_cat(province_id, city_id, 3)&#10;    for task in tasks:&#10;        # 实时播报&#10;        global count&#10;        count += 1&#10;        # 时间&#10;        p_time = task[4]&#10;        p_time = p_time.isoformat()[:10]&#10;        print(count, p_time, task[0], task[1], task[2])&#10;        # 处理数据&#10;        title = task[2]&#10;        url = task[1]&#10;        task_id = task[0]&#10;        get_data_3(url, title, p_time, task_id)&#10;    print(&quot;======city_id:{}, type_id{}======&quot;.format(city_id, 3))&#10;    print(&quot;======完成======&quot;)&#10;&#10;&#10;@i_api.exception_log(('city_id: ' + str(city_id) + 'type_id:' + str(3)))&#10;def get_data_3(url, title, public_time, task_id):&#10;    html = i_api.html_xpath(url)&#10;    # 主要内容的xpath&#10;    main_xpath = &quot;$xpath$&quot;&#10;    is_save = False&#10;    if i_api.data_is_table(html, main_xpath):&#10;        i_api.save_table_to_huanping(province_id, city_id, 3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;    elif i_api.data_is_para(html, main_xpath):&#10;        i_api.save_para_to_huanping(province_id, city_id,3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                    min_num=8, to_save=is_save)&#10;    elif i_api.data_is_aline(html, main_xpath):&#10;        i_api.save_aline_to_huanping(province_id, city_id, 3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     min_num=8, to_save=is_save)&#10;    else:&#10;        i_api.save_title_to_huanping(province_id, city_id, 3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;&#10;if __name__ == '__main__':&#10;    parse_task_3()&#10;" description="new_获取环评3" toReformat="false" toShortenFQNames="true">
    <variable name="xpath" expression="" defaultValue="" alwaysStopAt="true" />
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="hp123" value="# -*- coding:utf-8 -*-&#10;'''&#10;__author__ = 'XD'&#10;__mtime__ = 2019/1/21&#10;__project__ = cube&#10;Fix the Problem, Not the Blame.&#10;'''&#10;'''&#10;流程：&#10;1. parse_task: 获取task，并将数据传给get_data&#10;2. get_data: 解析页面数据，把数据存入data字典，然后传入i_api.save_huanping(data, province_id, city_id, type_id)保存数据&#10;'''&#10;from urllib.parse import urljoin&#10;from iWork.dbapi.api import get_tasks_with_cat&#10;from iWork import i_api&#10;from pprint import pprint&#10;import re&#10;&#10;# 计数&#10;count = 0&#10;# 城市信息&#10;city_id = $city_id$&#10;province_id = $province_id$&#10;&#10;&#10;def parse_task_1():&#10;    # 获取本市未爬取的url&#10;    tasks = get_tasks_with_cat(province_id, city_id, 1)&#10;    for task in tasks:&#10;        # 实时播报&#10;        global count&#10;        count += 1&#10;        # 时间&#10;        p_time = task[4]&#10;        p_time = p_time.isoformat()[:10]&#10;        print(count, p_time, task[0], task[1], task[2])&#10;        # 处理数据&#10;        title = task[2]&#10;        url = task[1]&#10;        task_id = task[0]&#10;        get_data_1(url, title, p_time, task_id)&#10;    print(&quot;======city_id:{}, type_id{}======&quot;.format(city_id, 1))&#10;    print(&quot;======完成======&quot;)&#10;&#10;&#10;@i_api.exception_log(('city_id: ' + str(city_id) + 'type_id:' + str(1)))&#10;def get_data_1(url, title, public_time, task_id):&#10;    html = i_api.html_xpath(url)&#10;    # 主要内容的xpath&#10;    main_xpath = &quot;$xpath$&quot;&#10;    is_save = False&#10;    if i_api.data_is_table(html, main_xpath):&#10;        i_api.save_table_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;    elif i_api.data_is_para(html, main_xpath):&#10;        i_api.save_para_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                    min_num=8, to_save=is_save)&#10;    elif i_api.data_is_aline(html, main_xpath):&#10;        i_api.save_aline_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     min_num=8, to_save=is_save)&#10;    else:&#10;        i_api.save_title_to_huanping(province_id, city_id, 1, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;&#10;&#10;def parse_task_2():&#10;    # 获取本市未爬取的url&#10;    tasks = get_tasks_with_cat(province_id, city_id, 2)&#10;    for task in tasks:&#10;        # 实时播报&#10;        global count&#10;        count += 1&#10;        # 时间&#10;        p_time = task[4]&#10;        p_time = p_time.isoformat()[:10]&#10;        print(count, p_time, task[0], task[1], task[2])&#10;        # 处理数据&#10;        title = task[2]&#10;        url = task[1]&#10;        task_id = task[0]&#10;        get_data_2(url, title, p_time, task_id)&#10;    print(&quot;======city_id:{}, type_id{}======&quot;.format(city_id, 2))&#10;    print(&quot;======完成======&quot;)&#10;&#10;&#10;@i_api.exception_log(('city_id: ' + str(city_id) + 'type_id:' + str(2)))&#10;def get_data_2(url, title, public_time, task_id):&#10;    html = i_api.html_xpath(url)&#10;    # 主要内容的xpath&#10;    main_xpath = &quot;$xpath$&quot;&#10;    is_save = False&#10;    if i_api.data_is_table(html, main_xpath):&#10;        i_api.save_table_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;    elif i_api.data_is_para(html, main_xpath):&#10;        i_api.save_para_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                    min_num=8, to_save=is_save)&#10;    elif i_api.data_is_aline(html, main_xpath):&#10;        i_api.save_aline_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     min_num=8, to_save=is_save)&#10;    else:&#10;        i_api.save_title_to_huanping(province_id, city_id, 2, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;&#10;&#10;def parse_task_3():&#10;    # 获取本市未爬取的url&#10;    tasks = get_tasks_with_cat(province_id, city_id, 3)&#10;    for task in tasks:&#10;        # 实时播报&#10;        global count&#10;        count += 1&#10;        # 时间&#10;        p_time = task[4]&#10;        p_time = p_time.isoformat()[:10]&#10;        print(count, p_time, task[0], task[1], task[2])&#10;        # 处理数据&#10;        title = task[2]&#10;        url = task[1]&#10;        task_id = task[0]&#10;        get_data_3(url, title, p_time, task_id)&#10;    print(&quot;======city_id:{}, type_id{}======&quot;.format(city_id, 3))&#10;    print(&quot;======完成======&quot;)&#10;&#10;&#10;@i_api.exception_log(('city_id: ' + str(city_id) + 'type_id:' + str(3)))&#10;def get_data_3(url, title, public_time, task_id):&#10;    html = i_api.html_xpath(url)&#10;    # 主要内容的xpath&#10;    main_xpath = &quot;$xpath$&quot;&#10;    is_save = False&#10;    if i_api.data_is_table(html, main_xpath):&#10;        i_api.save_table_to_huanping(province_id, city_id, 3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;    elif i_api.data_is_para(html, main_xpath):&#10;        i_api.save_para_to_huanping(province_id, city_id, 3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                    min_num=8, to_save=is_save)&#10;    elif i_api.data_is_aline(html, main_xpath):&#10;        i_api.save_aline_to_huanping(province_id, city_id, 3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     min_num=8, to_save=is_save)&#10;    else:&#10;        i_api.save_title_to_huanping(province_id, city_id, 3, task_id, url, title, public_time, html, xpath=main_xpath,&#10;                                     to_save=is_save)&#10;&#10;&#10;if __name__ == '__main__':&#10;    parse_task_1()&#10;    parse_task_2()&#10;    parse_task_3()&#10;" description="new_huanping123" toReformat="false" toShortenFQNames="true">
    <variable name="city_id" expression="" defaultValue="" alwaysStopAt="true" />
    <variable name="province_id" expression="" defaultValue="" alwaysStopAt="true" />
    <variable name="xpath" expression="" defaultValue="" alwaysStopAt="true" />
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
</templateSet>